% !TeX root = ../main.tex
% -*- coding: utf-8 -*-

\chapter{基于生成对抗网络特征提取的近边界数据研究}\label{3}

本章将从近边界对抗性样本出发，引出近边界数据，并详细阐述生成私有近边界数据的方法。

\section{近边界对抗性样本}

在\ref{5}\ref{5.3}中，本文通过大量的实验证明了近边界数据在大多数模型窃取攻击中，其近边界特征在盗窃模型中被保留。因此，近边界数据可以作为推断深度神经网络模型所有权的依据使用。下面给出近边界数据的定义：

\begin{myDef}
	\label{def:1}
	\pmb{近边界数据}。给定一个数据样本$x$，一个阈值$\theta$,如果数据样本$x$满足$\vert g_i(x) - g_j(x) \vert \leq \theta$，其中$i \neq j $并且$min(g_i(x), g_j(x)) \geq \mathop{max} \limits_{k \neq i, j}g_k(x)$，$g_k(x)$代表数据样本$x$决策为类别$k$的概率，则数据样本$x$被称为近边界数据。
\end{myDef}


\section{CW生成近边界对抗性样本}\label{3.2}

尽管近边界在模型的知识产权保护中表现出显著的效果，但是自然的近边界数据在样本空间中的占比很低，甚至可以忽略，因此如何得到一定规模的近边界数据样本仍然很困难。

根据最近的一些研究\cite{cao2021ipguard}，对抗性样本通常被用于确定分类器的分类边界。具体而言，对抗性样本有两个分类：原始分类和目标分类。其中，原始分类是该样本不经过特殊处理的原始分类结果，目标分类是对原始样本添加微小噪声后的分类结果。如图\ref{原始样本与对抗性样本对比}所示，对抗性样本对分类边界的跨越体现在，在视觉上对抗性样本和原始样本几乎没有差别，但是分类结果却是目标分类。

\begin{figure}[htbp]%%图,[htbp]是浮动格式
	\begin{minipage}[t]{0.5\linewidth}        %图片占用一行宽度的50%
		\hspace{2mm}
		\centering
		\includegraphics[width=5cm,height=3.5cm]{对抗性样本原图.jpg}
		\centerline{(a)原始样本}
	\end{minipage}
	\begin{minipage}[t]{0.5\linewidth}        %图片占用一行宽度的50%
		\hspace{2mm}
		\centering
		\includegraphics[width=5cm,height=3.5cm]{对抗性样本.jpg}
		\centerline{(b)对抗性样本}
	\end{minipage}
\setlength{\abovecaptionskip}{7mm} %图片标题与图片距离
\caption{原始样本与对抗性样本对比}
\label{原始样本与对抗性样本对比}
\end {figure}

本文认为该特征可以帮助从对抗性样本中获得较多的近边界数据。因此，本文测试了几种常用的生成对抗性样本的方法，以帮助我们构建近边界数据。

\noindent$\bm{Fast \ Gradient \ Sign \ Method(FGSM):}$FGSM \cite{goodfellow2014explaining}是最经典的构建对抗性样本的方法之一，它是一种基于梯度生成对抗性样本的方法，属于无目标攻击方式。只需要对原始样本添加微小的扰动$\eta$，如式\ref{eq:3.1}，\ref{eq:3.2}所示，即可生成样本$x$的对抗性样本$\tilde{x}$。

\begin{equation}
	\label{eq:3.1}
	\eta = \epsilon \cdot sign(\bigtriangledown_xJ(\theta,x,y^*))
\end{equation}
\begin{equation}
	\label{eq:3.2}
	\tilde{x} = clip(x + \eta)
\end{equation}

\noindent 其中$sign$是符号函数，$x$表示原始样本，$y^*$表示$x$的真实类别，$\theta$表示模型权重参数，$J$表示分类器损失函数，$\bigtriangledown_x$表示对原始样本$x$求偏导，$clip$函数是将样本投射回可行数据域，$\epsilon$用来控制变化幅度。

FGSM 生成对抗性样本的速度非常快，但其结果非常依赖$\epsilon$的选择，因此探索不同的$\epsilon$是使用该方法的重点。除此之外，我们还测试了许多FGSM 的进阶版本如IGSM和RFSGM, 它们引入了迭代加入噪声和弱扰动的方法。IGSM 迭代式地使样本跨越分类边界直至成功，RFGSM 则是增加了扰动的多样性，可以更精细地生成对抗性样本。在实际结果中我们发现FGSM 生成对抗性示例尽管速度非常快，但位于分类边界附近的数据比例却极低。IGSM 和RFGSM 效果要比FGSM 好，但仍认为不符合我们的期望。在大量的测试中，我们发现CW能够生成大量在分类边界附近的样本，具体的测试结果在\ref{5}\ref{5.2}中。

\noindent$\bm{Carlini \ and \ Wagner's \ methods(CW):}$CW \cite{carlini2017towards}方法同样是添加噪声到对抗性样本中，但其具有三种变体：CW-$L_0$，CW-$L_2$和CW-$L_{\infty}$，不同的变体使用不同的方法来衡量噪声的大小，其中CW-$L_2$在实验中效果最为突出，因此本文使用该方法作为生成对抗性样本的选择。具体而言，CW-$L_2$对于给定的初始样本迭代搜索一个小噪声使示例变为对抗性样本，这种思路使得生成的对抗性样本都集中在分类边界附近，但相应地，CW-$L_2$牺牲了效率。

在这一阶段，我们只是在源模型的样本空间中挑选一部分数据作为初始样本添加小噪声，针对性地生成了目标分类对抗性样本。在此阶段源模型的训练和原始数据均不受任何影响，防御者只需要针对性的生成对抗性示例即可。然而，近边界数据作为推断所有权的重要证据，直接生成对抗性样本也极易受到盗窃者的复制。因此，我们需要将生成的近边界数据私有化，具体操作将在\ref{3}\ref{3.3}中给出。

\section{近边界数据私有化}\label{3.3}

由于通过生成对抗性样本的方法构建近边界数据这一步骤十分容易复现，并且现在大多数模型训练使用的数据都来源于公开数据。因此我们需要从公开的训练数据中构建自己私有化的近边界数据，以防止模型所有者的近边界数据被轻易模仿。在本文中，我们希望可以通过训练一种模型学习\ref{3}\ref{3.2}中近边界对抗性样本的特征，并以此生成新的近边界数据。这种新的数据从视觉上不一定和原始数据类似，但其原始的特征以及添加的噪声需要被学习，并根据提取到的特征生成的新样本对于源模型同样是近边界数据。因此，在本文中我们设计了一种基于DCGAN\cite{radford2015unsupervised}的特征提取器，提取近边界数据的特征之后作为近边界数据生成器并将近边界数据私有化。注意生成器以，$CW$-$L_2$生成的对抗性示例作为输入，并输出私有化后的近边界数据。

具体而言，DCGAN 的结构中包括一个判定器D 和一个生成器G，其本质上是一个博弈过程。生成器学习样本特征生成假数据，判定器判断生成器的结果。DCGAN 的目标函数如\ref{eq:3.3}所示，是一个生成网络和判别网络的互相对抗的过程，生成器尽可能生成逼真输入样本，判别器则尽可能去判别该样本是真实样本还是假样本。
\begin{equation}
	\label{eq:3.3}
	\begin{split}
		\mathop{min} \limits_{G} \mathop{max} \limits_{D} V(D, G) &= \mathop{min} \limits_{G} \mathop{max} \limits_{D} E_{x \sim P_{data}(x)}[logD(x)] \\
		&+ E_{T \sim P_{T}(T)}[log(1 - D(G(T)))]
	\end{split}
\end{equation}
其中$x$表示真实数据样本，$T$表示用于生成样本的随机噪声，GAN对噪声$z$的分布没有特别要求，但是常用的有高斯分布，均匀分布。注意这里的优化过程是一个交替的过程。

我们希望DCGAN能够学习到足够多的近边界数据特征，尝试修改其判定器的目标函数，在保留梯度的情况下将其与源模型的结果相连，得到的结果在同样的生成规模下确实优于原始DCGAN 的生成情况。然而，考虑到在两者的效率，实际情况下生成的结果并无较大区别。

尽管构建的近边界数据已经都位于目标分类边界附近，但我们仍希望近边界数据最大程度上靠近目标分类边界。近边界数据与目标分类边界的距离越近，推断模型所有权成功的可能性就越大。此外，生成的近边界数据虽然只被模型所有者拥有，但对于一些功能易被泛化的模型，近边界的特性仍有可能被泛化。因此，本文提出使用近边界数据微调源模型的目标分类边界。具体而言，如\ref{eq:3.4}所示，$Loss_{FT}$是针对目标分类边界的损失函数，其中$n$是该目标分类边界的近边界数据的数量，$x_i'$是生成的近边界数据，$g_t(\cdot)$和$g_s(\cdot)$分别表示目标分类概率和源分类概率，$Loss_{FT}$本质是希望近边界数据更靠近目标分类边界$Loss_{FM}$是源模型的损失函数，我们设计两者交替训练微调源模型，与DCGAN 的过程相似，是一个博弈的过程。

\begin{equation}
	\label{eq:3.4}
	Loss_{FT} = \frac{1}{n} \sum^{n}_{i = 1} (g_t(x_i') - g_s(x_i'))^2
\end{equation}

微调目标分类边界使近边界数据与源模型之间的联系更加紧密。注意，我们只微调目标分类边界，且通过交替微调尽可能减少微调对源模型的影响，如表\ref{table:state}所示，微调前后源模型的精度差不超过5\%，因此，微调对于源模型的性能影响十分微小，甚至可以被忽略，但却有效提高了最后的所有权推断效果。更多的准确度测试结果可以在\ref{5}\ref{5.5}中找到。

\begin{table}[H]
	\centering
	\setlength{\arrayrulewidth}{0.5mm}
	\renewcommand\arraystretch{1.8}
	\caption{微调分类边界对模型的影响}
	\label{table:state}
	\begin{tabular*}{13cm}{@{\extracolsep{\fill}} l c c}
		
		\hline
		数据集        &    微调前准确率   &   微调后准确率            \\
		\hline
		CIFAR-10      &     0.886        &     0.873               \\
		
		Heritage      &     0.879        &     0.856               \\
		
		Intel\_image  &     0.794        &     0.786               \\
		\hline		
	\end{tabular*}
\end{table}

\section{本章小结}

本章介绍了近边界数据的特征，并详细阐述了生成私有近边界数据的方法。首先通过CW方法，生成近边界对抗性样本，然后利用对抗生成网络的学习特征，将近边界数据私有化，最后通过自定义损失函数交替微调源模型，在几乎不损失模型精度的情况下，使其近边界数据更加靠近分类边界。
