% !TeX root = ../main.tex
% -*- coding: utf-8 -*-

\chapter{绪论}
\label{1}


\section{研究背景与意义}

近年来，科技迅速发展，计算资源日益丰富，计算能力得到显著提升，我们正在进入人工智能(Artificial Intelligence, AI)\cite{winston1984artificial}的时代。随着互联网的的快速发展，产生了海量的数据，得益于深度神经网络(Deep Neural Network, DNN)\cite{sze2017efficient}强大的数据处理能力，DNN已经成为应用最广泛的人工智能方法之一。自DNN在计算机视觉\cite{he2016identity,cortes2015advances,simonyan2014very}，语音识别\cite{nassif2019speech}，自然语言处理\cite{collobert2011natural,wu2016google,xiong2016achieving}等方面上突破性应用以来，使用DNN的应用数量呈爆炸式增长。这些DNN应用被应用到从自动驾驶\cite{chen2015deepdriving}到癌症检测\cite{esteva2017dermatologist}到玩复杂的游戏\cite{silver2017mastering}等无数应用中。并且在许多这些领域中，DNN已经能够超越人类的准确性。

DNN在许多领域取得巨大成功，为人类社会生活带来极大便利的同时，也带来了非常严重的侵犯知识产权(Intellectual Property, IP)问题。训练一个大型的高性能的DNN模型都离不开该领域专家的专业知识、规模巨大的数据集以及大量的训练时间和强大的计算资源，具体体现在以下三个方面：
\begin{enumerate}
	\renewcommand{\labelenumi}{\theenumi)}
	\item 人力资源，对于不同场景不同目的的DNN模型，需要不同领域的知识，包含对模型结构的设计分析、模型参数的调试校验等；
	\item 大量的训练数据，模型所有者要在特定领域训练出一个高性能的模型，通常需要该领域大量的数据，并且需要覆盖到应用场景中的各种情况，这些数据的获取和整理本身就需要昂贵的价格，有的领域的数据还涉及到隐私性问题；
	\item 昂贵的计算资源和大量的训练时间，DNN模型的规模越来越大，层数越来越多，需要的训练时间也越多，并且训练过程中也需要越来越多的计算资源支持，才能对网络权重等进行精确的调整，这些都是巨额的经济成本。如GPT-3\cite{brown2020language}，包含了1750亿参数，仅训练成本需花费460万美元以上。
\end{enumerate}
所以高性能DNN模型是模型所有者智慧的结晶，同时需要高额的经济开销，模型所有者享有DNN模型的知识产权\cite{chen2018performance,darvish2019deepsigns}。

模型所有者出于学术目的将DNN模型放到开源社区上。或者，使用机器学习即服务(Machine Learning as a Service, MLaaS)\cite{ribeiro2015mlaas}的商业模式，即MLaaS平台通过训练好的DNN模型来向用户提供应用程序接口(Application Programming Interface, API)\cite{ofoeda2019application}，用户可以通过支付一定的费用来使用API。或者，训练好的DNN模型将成为像我们日常商品一样的消费品，它们由不同的公司或个人进行训练，由不同的供应商分发，最终由用户消费。如图\ref{DNN模型服务和盗窃示意图}所示，这样的方式极大的方便了科研工作者和一般的消费者，但是不法分子却可以以比模型所有者低很多的成本复制一个替代模型，用于自己盈利。

\begin{figure}[htbp]%%图,[htbp]是浮动格式
	\centering
	\includegraphics[width=14.5cm,height=9cm]{DNN模型服务和盗窃示意图.pdf}
	%	\centerline{原始样本}
	\setlength{\abovecaptionskip}{5mm} %图片标题与图片距离
	\caption{DNN模型服务和盗窃示意图}
	\label{DNN模型服务和盗窃示意图}
	\end {figure}
	
所以如何在训练和部署时保护DNN模型所有者的知识产权是AI领域亟待解决的问题。


\section{相关研究现状}

作为一种数字产品，DNN模型不仅凝结了设计者的智慧，还需要消耗大量的训练数据和昂贵的计算资源。近年来，拥有先进的的模型带来的工业优势已经被人们广泛认可，这开始激发一些不法分子窃取这些模型的攻击\cite{tramer2016stealing,duddu2018stealing}。现在可以明确的是，DNN模型将在未来的IT发展中发挥核心作用，因此保护这些模型的必要性显得更加突出。1994年，Van Schyndel等人\cite{van1994digital}第一次提出数字水印的概念，将标记隐蔽的嵌入到如音频、视频等数字内容中，来识别其所有权，具体来说，版权所有者通过显示此类标记的存在可以证明其对内容的所有权。DNN模型也是一种数字产品，所以，许多研究者从数字媒体水印得到启发，从而设计模型水印和模型指纹用于解决DNN模型的所有权问题。

模型水印是解决DNN模型知识产权问题的主要方式之一，Uchida等人\cite{uchida2017embedding}在2017年首次提出了在DNN模型中嵌入水印的通用框架。该方法是一种白盒的模式，通过训练时使用正则化器，并且这种正则化在参数中引入了所需要的统计偏差来作为嵌入的水印。模型所有者清楚模型内部的细节，并且可以提取嵌入的水印，以此来作为模型所有权的依据\cite{nagai2018digital}。Fan等人\cite{fan2019rethinking}提出了一种在DNN模型中嵌入数字护照的方案，嵌入数字护照的要点是设计和训练DNN模型，使得在伪造护照的情况下DNN的推断性能显著下降，而真正的护照可以通过查找预定签名来验证。Chen等人\cite{chen2018deepmarks}提出了一种新颖的端到端框架，该框架同时依赖于用户和模型，它需要为每一个用户分配一个代码向量，并将该信息嵌入到可训练权重的的概率密度函数中，同时保持模型的准确性。不同于白盒的模式，另一种黑盒的模式，可以在不访问模型内部的情况下，通过特定的输入输出来验证模型的所有权。Le等人\cite{le2020adversarial}提出了一种零比特水印算法，该算法标记模型的操作本身，稍微调整它的决策边界，来使特定的查询得到特定的输出。在减少模型性能损失的同时，该算法可以远程操作DNN或API服务，通过少量的查询提取水印。Zhang等人\cite{zhang2018protecting}提出了一种水印植入方法，将水印注入DNN模型。通过扩展DNN的内在泛化和记忆能力，使得模型能够在训练时学习特意制作的水印，然后在推断时激活预先指定的预测。Adi等人\cite{adi2018turning}提出了利用模型的后门机制当作DNN模型水印。后门通常是DNN将输入预测为错误的标签，虽然在大多数情况下这是不可取的，但是却可以将为DNN模型制作水印的任务转化为设计后门的任务。这些黑盒的方法利用对抗性样本作为触发集，或者使用一组特定的训练样本，然后根据特殊样本的输出来提取水印。因此黑盒的方法在所有权验证中不需要访问模型的权重参数。Rouhani等人\cite{rouhani2018deepsigns}提出了一种端到端的IP保护框架DeepSigns，可以在DNN模型中插入连贯的数字水印。DeepSigns引入了一种通用水印方法，不同于直接将水印信息嵌入到模型的权重中，DeepSigns将任意N位字符串嵌入到各层激活集的概率密度函数中，这意味着水印信息嵌入在DNN的动态内容中，并且只能通过特定的输入数据来触发，并且对权重矩阵等静态属性没有影响。但是DNN模型水印的嵌入步骤总是会对原始进行修改。具体来说，白盒水印修改模型内部，比如模型权重，激活函数等，而黑盒水印通过特殊的训练调整模型来指定特定的输出。这些修改将会影响DNN模型在原始任务上的性能。

模型指纹是解决DNN模型知识产权问题的又一主流方法。不同与模型水印，模型指纹不需要对模型本身进行修改，而是利用模型本身来寻找和提取一些独特的特征作为模型指纹，一般来说，模型指纹不会影响模型的性能。Zhao等人\cite{zhao2020afa}提出了一种新的DNN模型指纹技术，该技术旨在提取模型本身的固有特征，而不是嵌入额外的水印。具体来说，该方法选择一组专门设计的对抗性样本作为模型指纹特征，称为对抗性标记，相比于其他不相关的模型，它可以更好的转移到从原始模型派生出的模型上。与Zhao等人\cite{zhao2020afa}的方法类似，Lukas等人\cite{lukas2019deep}提出了一种用于DNN分类器的指纹识别方法，该方法从源模型中提取一组输入，以便只有源模型的派生模型在此类输入的分类上与源模型一致。这些输入是可转移对抗性样本的一个子类，它们的目标标签会从源模型转移到其派生模型上。Cao等人\cite{cao2021ipguard}针对DNN分类器提出了一种名叫IPGuard的指纹方法，该方法的关键是DNN分类器可以由其分类边界唯一的表示。基于这一原理，IPGuard在模型所有者的DNN分类器分类边界上提取了一些数据点，并使用它们对分类器进行指纹识别，如果DNN分类器对大多数指纹数据点预测相同的标签，那么该模型被认为是模型所有者分类器的盗版。Li等人\cite{li2021novel}提出了一种适用于生成对抗网络(Generative Adversarial Network, GAN)\cite{goodfellow2020generative}知识产权保护的指纹识别方案。



\section{本文主要工作}

揭示\cite{maini2021dataset}现有问题，确认数据驱动推断所有权的有效性

利用对抗性样本抵御模型窃取

基于DCGAN生成私有数据

广泛实验验证有效性

\section{本文组织架构}

第一章

第二章

第三章

第四章

第五章

第六章